{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "import os\n",
    "import csv\n",
    "import time\n",
    "import math\n",
    "import scipy\n",
    "import xgboost as xgb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from numpy import genfromtxt\n",
    "\n",
    "import pickle\n",
    "import logging\n",
    "\n",
    "import glob\n",
    "import statistics\n",
    "import statsmodels.api as sm\n",
    "from statistics import mean\n",
    "from statistics import stdev\n",
    "from pytz import timezone\n",
    "from datetime import datetime\n",
    "from scipy.stats import shapiro\n",
    "from scipy.signal import resample\n",
    "from scipy.cluster.vq import kmeans\n",
    "from xgboost import plot_importance\n",
    "from matplotlib import pyplot\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_shape = pd.read_csv(f'./_results/norotate_looc_384.csv', skiprows = 0)  # LOOC\n",
    "df_shape = pd.read_csv(f'./_results/df_512_mask_all_210927.csv', skiprows = 0)  # Ours FINAL!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mask_columns = []\n",
    "\n",
    "for i in range(0,512):\n",
    "    df_mask_columns.append(\"all_\"+str(i))\n",
    "for i in range(0,512):\n",
    "    df_mask_columns.append(\"shape_\"+str(i))    \n",
    "for i in range(0,512):\n",
    "    df_mask_columns.append(\"color_\"+str(i))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_shape_mid1 = pd.concat([df_mask_all.iloc[:, :512], df_mask_shape.iloc[:, :512]], axis=1)\n",
    "df_shape_mid2 = pd.concat([df_shape_mid1, df_mask_color.iloc[:, :512]], axis=1)\n",
    "\n",
    "df_shape_mid2.columns = df_mask_columns\n",
    "df_shape_mid2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_shape = pd.concat([df_shape_mid2, df_mask_all.iloc[:, 512:]], axis=1)\n",
    "df_shape.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shape_dim = 512*3  # 384; 512; 512*3\n",
    "df_shape_only = pd.concat([df_shape.iloc[:, shape_dim], df_shape.iloc[:, 0:shape_dim]], axis=1)\n",
    "df_shape_only.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Feature-engineered Features\n",
    "\n",
    "bins_no = 128  # = 32, 128, 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_col_seg_meta_raw = pd.concat([df_shape.iloc[:, shape_dim], df_shape.iloc[:, shape_dim+1:]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'./_results/total_df_RGBHSV_ent_seg_rgbHistBin{bins_no}_meta.pkl', 'rb') as f:\n",
    "    object_df = pickle.load(f)\n",
    "    \n",
    "df_col_seg_meta_raw = pd.DataFrame(object_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## [START] Y-label: gender\n",
    "\n",
    "print(np.unique(df_col_seg_meta_raw['gender'].values))\n",
    "len(np.unique(df_col_seg_meta_raw['gender'].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_col_seg_meta_raw['gender'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_col_seg_meta_mid = df_col_seg_meta_raw.loc[(df_col_seg_meta_raw['gender'] == 'child') | \n",
    "                                              (df_col_seg_meta_raw['gender'] == 'preschool') | \n",
    "                                              (df_col_seg_meta_raw['gender'] == 'toddler') |\n",
    "                                              (df_col_seg_meta_raw['gender'] == 'women')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "men_list = df_col_seg_meta_raw.loc[df_col_seg_meta_raw['gender'] == \"men\"].index.values.tolist()\n",
    "sample_random = random.sample(men_list, 3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_men_only = df_col_seg_meta_raw.loc[sample_random]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_col_seg_meta = pd.concat([df_men_only, df_col_seg_meta_mid])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_col_seg_meta.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_col_seg_meta['gender'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_col_seg_meta.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison_column = np.where(df_col_seg_meta[\"image_fileName\"] == df_col_seg_meta[\"id\"], True, False)\n",
    "\n",
    "m=0\n",
    "for x in comparison_column:\n",
    "    if x == False:\n",
    "        m += 1\n",
    "print(m)\n",
    "\n",
    "## [END] Y-label: gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## [START] Y-label: primaryCategory\n",
    "\n",
    "print(np.unique(df_col_seg_meta_raw['primaryCategory'].values))\n",
    "len(np.unique(df_col_seg_meta_raw['primaryCategory'].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_col_seg_meta_raw['primaryCategory'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_col_seg_meta = df_col_seg_meta_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_col_seg_meta = df_col_seg_meta_raw.loc[(df_col_seg_meta_raw['primaryCategory'] != 'SPO') & (df_col_seg_meta_raw['primaryCategory'] != 'Nike Training') &\n",
    "                                          (df_col_seg_meta_raw['primaryCategory'] != 'Nike Running') & (df_col_seg_meta_raw['primaryCategory'] != 'Luxury Brands') &\n",
    "                                          (df_col_seg_meta_raw['primaryCategory'] != 'Foamposite') & (df_col_seg_meta_raw['primaryCategory'] != 'KD') &\n",
    "                                          (df_col_seg_meta_raw['primaryCategory'] != 'Nike Other') & (df_col_seg_meta_raw['primaryCategory'] != 'Other Brands')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_col_seg_meta['primaryCategory'].value_counts())\n",
    "len(df_col_seg_meta['primaryCategory'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_col_seg_meta.shape\n",
    "\n",
    "## [END] Y-label: primaryCategory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## [START] Y-label: maxResellPrice\n",
    "\n",
    "df_maxResell = pd.read_csv(f'./_results/max_resell_prices_Bre_210917.csv', skiprows = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "for val in df_maxResell:\n",
    "    print(i, val)\n",
    "    i += 1\n",
    "    \n",
    "print('\\n', \"Total # of features:\", str(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_maxResell_premium = df_maxResell.iloc[:, 7:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_maxResell_premium.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_maxResell_premium.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.hist(df_maxResell_premium['inflated_profit'], bins=100, label='bins=100')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# QQ Plot\n",
    "from numpy.random import seed\n",
    "from numpy.random import randn\n",
    "from statsmodels.graphics.gofplots import qqplot\n",
    "from matplotlib import pyplot\n",
    "\n",
    "# seed the random number generator\n",
    "seed(1)\n",
    "# generate univariate observations\n",
    "data = 5 * randn(100) + 50\n",
    "qqplot(data, line='s')\n",
    "pyplot.show()\n",
    "\n",
    "# q-q plot\n",
    "qqplot(df_maxResell_premium['inflated_profit'], line='s')\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stat, p = shapiro(df_maxResell_premium['inflated_profit'])\n",
    "print('Statistics=%.3f, p=%.3f' % (stat, p))\n",
    "\n",
    "# interpret\n",
    "alpha = 0.05\n",
    "if p > alpha:\n",
    "    print('Sample looks Gaussian (fail to reject H0)')\n",
    "else:\n",
    "    print('Sample does not look Gaussian (reject H0)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"20th percentile: \", np.percentile(df_maxResell_premium['inflated_profit'], 20))\n",
    "print(\"25th percentile: \", np.percentile(df_maxResell_premium['inflated_profit'], 25))\n",
    "print(\"50th percentile: \", np.percentile(df_maxResell_premium['inflated_profit'], 50))\n",
    "print(\"75th percentile: \", np.percentile(df_maxResell_premium['inflated_profit'], 75))\n",
    "print(\"80th percentile: \", np.percentile(df_maxResell_premium['inflated_profit'], 80))\n",
    "\n",
    "pct_20 = np.percentile(df_maxResell_premium['inflated_profit'], 20)\n",
    "pct_80 = np.percentile(df_maxResell_premium['inflated_profit'], 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mid_premium_lower = df_maxResell_premium.loc[(df_maxResell_premium['inflated_profit']< pct_80)]\n",
    "df_bin_premium_upper = df_maxResell_premium.loc[(df_maxResell_premium['inflated_profit']>=pct_80)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bin_premium_lower = df_mid_premium_lower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "premium_lower_list = df_mid_premium_lower.index.values.tolist()\n",
    "premium_lower_sample = random.sample(premium_lower_list, len(df_bin_premium_upper))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bin_premium_lower = df_mid_premium_lower[df_mid_premium_lower.index.isin(premium_lower_sample)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bin_premium_lower['bin_premium'] = \"premium_lower\"\n",
    "df_bin_premium_upper['bin_premium'] = \"premium_upper\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bin_premium = pd.concat([df_bin_premium_lower, df_bin_premium_upper])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bin_premium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## [END] Y-label: maxResellPrice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize by z-score by column\n",
    "\n",
    "col_zscore = ['mean_b', 'mean_g', 'mean_r', 'std_b', 'std_g',\n",
    "       'std_r', 'mean_h', 'mean_s', 'mean_v', 'std_h', 'std_s', 'std_v',\n",
    "       'ent_b', 'ent_g', 'ent_r', 'ent_h', 'ent_s', 'ent_v', 'ent_grey',\n",
    "       'mean_area', 'std_area', 'mean_perimeter', 'std_perimeter',\n",
    "       'num_segments', 'B_hist_0', 'B_hist_1', 'B_hist_2', 'B_hist_3',\n",
    "       'B_hist_4', 'B_hist_5', 'B_hist_6', 'B_hist_7', 'B_hist_8',\n",
    "       'B_hist_9', 'B_hist_10', 'B_hist_11', 'B_hist_12', 'B_hist_13',\n",
    "       'B_hist_14', 'B_hist_15', 'B_hist_16', 'B_hist_17', 'B_hist_18',\n",
    "       'B_hist_19', 'B_hist_20', 'B_hist_21', 'B_hist_22', 'B_hist_23',\n",
    "       'B_hist_24', 'B_hist_25', 'B_hist_26', 'B_hist_27', 'B_hist_28',\n",
    "       'B_hist_29', 'B_hist_30', 'B_hist_31', 'B_hist_32', 'B_hist_33',\n",
    "       'B_hist_34', 'B_hist_35', 'B_hist_36', 'B_hist_37', 'B_hist_38',\n",
    "       'B_hist_39', 'B_hist_40', 'B_hist_41', 'B_hist_42', 'B_hist_43',\n",
    "       'B_hist_44', 'B_hist_45', 'B_hist_46', 'B_hist_47', 'B_hist_48',\n",
    "       'B_hist_49', 'B_hist_50', 'B_hist_51', 'B_hist_52', 'B_hist_53',\n",
    "       'B_hist_54', 'B_hist_55', 'B_hist_56', 'B_hist_57', 'B_hist_58',\n",
    "       'B_hist_59', 'B_hist_60', 'B_hist_61', 'B_hist_62', 'B_hist_63',\n",
    "       'B_hist_64', 'B_hist_65', 'B_hist_66', 'B_hist_67', 'B_hist_68',\n",
    "       'B_hist_69', 'B_hist_70', 'B_hist_71', 'B_hist_72', 'B_hist_73',\n",
    "       'B_hist_74', 'B_hist_75', 'B_hist_76', 'B_hist_77', 'B_hist_78',\n",
    "       'B_hist_79', 'B_hist_80', 'B_hist_81', 'B_hist_82', 'B_hist_83',\n",
    "       'B_hist_84', 'B_hist_85', 'B_hist_86', 'B_hist_87', 'B_hist_88',\n",
    "       'B_hist_89', 'B_hist_90', 'B_hist_91', 'B_hist_92', 'B_hist_93',\n",
    "       'B_hist_94', 'B_hist_95', 'B_hist_96', 'B_hist_97', 'B_hist_98',\n",
    "       'B_hist_99', 'B_hist_100', 'B_hist_101', 'B_hist_102',\n",
    "       'B_hist_103', 'B_hist_104', 'B_hist_105', 'B_hist_106',\n",
    "       'B_hist_107', 'B_hist_108', 'B_hist_109', 'B_hist_110',\n",
    "       'B_hist_111', 'B_hist_112', 'B_hist_113', 'B_hist_114',\n",
    "       'B_hist_115', 'B_hist_116', 'B_hist_117', 'B_hist_118',\n",
    "       'B_hist_119', 'B_hist_120', 'B_hist_121', 'B_hist_122',\n",
    "       'B_hist_123', 'B_hist_124', 'B_hist_125', 'B_hist_126',\n",
    "       'B_hist_127', 'G_hist_0', 'G_hist_1', 'G_hist_2', 'G_hist_3',\n",
    "       'G_hist_4', 'G_hist_5', 'G_hist_6', 'G_hist_7', 'G_hist_8',\n",
    "       'G_hist_9', 'G_hist_10', 'G_hist_11', 'G_hist_12', 'G_hist_13',\n",
    "       'G_hist_14', 'G_hist_15', 'G_hist_16', 'G_hist_17', 'G_hist_18',\n",
    "       'G_hist_19', 'G_hist_20', 'G_hist_21', 'G_hist_22', 'G_hist_23',\n",
    "       'G_hist_24', 'G_hist_25', 'G_hist_26', 'G_hist_27', 'G_hist_28',\n",
    "       'G_hist_29', 'G_hist_30', 'G_hist_31', 'G_hist_32', 'G_hist_33',\n",
    "       'G_hist_34', 'G_hist_35', 'G_hist_36', 'G_hist_37', 'G_hist_38',\n",
    "       'G_hist_39', 'G_hist_40', 'G_hist_41', 'G_hist_42', 'G_hist_43',\n",
    "       'G_hist_44', 'G_hist_45', 'G_hist_46', 'G_hist_47', 'G_hist_48',\n",
    "       'G_hist_49', 'G_hist_50', 'G_hist_51', 'G_hist_52', 'G_hist_53',\n",
    "       'G_hist_54', 'G_hist_55', 'G_hist_56', 'G_hist_57', 'G_hist_58',\n",
    "       'G_hist_59', 'G_hist_60', 'G_hist_61', 'G_hist_62', 'G_hist_63',\n",
    "       'G_hist_64', 'G_hist_65', 'G_hist_66', 'G_hist_67', 'G_hist_68',\n",
    "       'G_hist_69', 'G_hist_70', 'G_hist_71', 'G_hist_72', 'G_hist_73',\n",
    "       'G_hist_74', 'G_hist_75', 'G_hist_76', 'G_hist_77', 'G_hist_78',\n",
    "       'G_hist_79', 'G_hist_80', 'G_hist_81', 'G_hist_82', 'G_hist_83',\n",
    "       'G_hist_84', 'G_hist_85', 'G_hist_86', 'G_hist_87', 'G_hist_88',\n",
    "       'G_hist_89', 'G_hist_90', 'G_hist_91', 'G_hist_92', 'G_hist_93',\n",
    "       'G_hist_94', 'G_hist_95', 'G_hist_96', 'G_hist_97', 'G_hist_98',\n",
    "       'G_hist_99', 'G_hist_100', 'G_hist_101', 'G_hist_102',\n",
    "       'G_hist_103', 'G_hist_104', 'G_hist_105', 'G_hist_106',\n",
    "       'G_hist_107', 'G_hist_108', 'G_hist_109', 'G_hist_110',\n",
    "       'G_hist_111', 'G_hist_112', 'G_hist_113', 'G_hist_114',\n",
    "       'G_hist_115', 'G_hist_116', 'G_hist_117', 'G_hist_118',\n",
    "       'G_hist_119', 'G_hist_120', 'G_hist_121', 'G_hist_122',\n",
    "       'G_hist_123', 'G_hist_124', 'G_hist_125', 'G_hist_126',\n",
    "       'G_hist_127', 'R_hist_0', 'R_hist_1', 'R_hist_2', 'R_hist_3',\n",
    "       'R_hist_4', 'R_hist_5', 'R_hist_6', 'R_hist_7', 'R_hist_8',\n",
    "       'R_hist_9', 'R_hist_10', 'R_hist_11', 'R_hist_12', 'R_hist_13',\n",
    "       'R_hist_14', 'R_hist_15', 'R_hist_16', 'R_hist_17', 'R_hist_18',\n",
    "       'R_hist_19', 'R_hist_20', 'R_hist_21', 'R_hist_22', 'R_hist_23',\n",
    "       'R_hist_24', 'R_hist_25', 'R_hist_26', 'R_hist_27', 'R_hist_28',\n",
    "       'R_hist_29', 'R_hist_30', 'R_hist_31', 'R_hist_32', 'R_hist_33',\n",
    "       'R_hist_34', 'R_hist_35', 'R_hist_36', 'R_hist_37', 'R_hist_38',\n",
    "       'R_hist_39', 'R_hist_40', 'R_hist_41', 'R_hist_42', 'R_hist_43',\n",
    "       'R_hist_44', 'R_hist_45', 'R_hist_46', 'R_hist_47', 'R_hist_48',\n",
    "       'R_hist_49', 'R_hist_50', 'R_hist_51', 'R_hist_52', 'R_hist_53',\n",
    "       'R_hist_54', 'R_hist_55', 'R_hist_56', 'R_hist_57', 'R_hist_58',\n",
    "       'R_hist_59', 'R_hist_60', 'R_hist_61', 'R_hist_62', 'R_hist_63',\n",
    "       'R_hist_64', 'R_hist_65', 'R_hist_66', 'R_hist_67', 'R_hist_68',\n",
    "       'R_hist_69', 'R_hist_70', 'R_hist_71', 'R_hist_72', 'R_hist_73',\n",
    "       'R_hist_74', 'R_hist_75', 'R_hist_76', 'R_hist_77', 'R_hist_78',\n",
    "       'R_hist_79', 'R_hist_80', 'R_hist_81', 'R_hist_82', 'R_hist_83',\n",
    "       'R_hist_84', 'R_hist_85', 'R_hist_86', 'R_hist_87', 'R_hist_88',\n",
    "       'R_hist_89', 'R_hist_90', 'R_hist_91', 'R_hist_92', 'R_hist_93',\n",
    "       'R_hist_94', 'R_hist_95', 'R_hist_96', 'R_hist_97', 'R_hist_98',\n",
    "       'R_hist_99', 'R_hist_100', 'R_hist_101', 'R_hist_102',\n",
    "       'R_hist_103', 'R_hist_104', 'R_hist_105', 'R_hist_106',\n",
    "       'R_hist_107', 'R_hist_108', 'R_hist_109', 'R_hist_110',\n",
    "       'R_hist_111', 'R_hist_112', 'R_hist_113', 'R_hist_114',\n",
    "       'R_hist_115', 'R_hist_116', 'R_hist_117', 'R_hist_118',\n",
    "       'R_hist_119', 'R_hist_120', 'R_hist_121', 'R_hist_122',\n",
    "       'R_hist_123', 'R_hist_124', 'R_hist_125', 'R_hist_126',\n",
    "       'R_hist_127']\n",
    "\n",
    "for col in col_zscore:\n",
    "    col_zscore = col + '_zscore'\n",
    "    df_col_seg_meta[col_zscore] = (df_col_seg_meta[col] - df_col_seg_meta[col].mean())/df_col_seg_meta[col].std(ddof=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_col_seg_meta.name_main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(np.unique(df_col_seg_meta.name_main))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "duplicate = df_col_seg_meta[df_col_seg_meta.duplicated(\"name_main\", keep=False)]\n",
    "print(\"Duplicate Rows :\")\n",
    "\n",
    "duplicate_sorted = duplicate.sort_values('name_main', ascending=True)\n",
    "print(duplicate_sorted.name_main)\n",
    "print(len(duplicate.name_main))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_col_seg_meta['colorway'][df_col_seg_meta['image_fileName'] == '7286aefd-fb03-4d8f-a0bd-fc5d7e25d698'])\n",
    "print(df_col_seg_meta['releaseDate'][df_col_seg_meta['image_fileName'] == '7286aefd-fb03-4d8f-a0bd-fc5d7e25d698'])\n",
    "print(df_col_seg_meta['colorway'][df_col_seg_meta['image_fileName'] == '5085591a-e428-4ea3-b544-3fd47f68606e'])\n",
    "print(df_col_seg_meta['releaseDate'][df_col_seg_meta['image_fileName'] == '5085591a-e428-4ea3-b544-3fd47f68606e'])\n",
    "\n",
    "## Discard duplicated images:\n",
    "# 5085591a-e428-4ea3-b544-3fd47f68606e\n",
    "# 052fea39-a685-48fd-899d-c48887f81505\n",
    "# 1bf72993-efab-4b42-b349-9d36caa94e63\n",
    "# 093f1287-bd2d-42e9-bdf4-3c937d396e3c\n",
    "# 6cb3aaf0-7932-4a14-8a1a-c2fb1a856b46"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Inference: Total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_col_seg_meta['releaseYear'] = df_col_seg_meta.releaseDate.str.split(\"-\", n=1, expand=True)[0]\n",
    "# df_col_seg_meta['brand']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_col_seg_meta['releaseYear'] = df_col_seg_meta['releaseYear'].replace(['1/1/05','1/1/12','10/3/12','11/28/12','12/8/12','4/16/12','5/10/17','5/4/13','6/24/17','6/28/17','6/30/17','7/15/17','7/2/17','7/6/17','8/5/17','9/30/17'],\n",
    "                                                                        ['2005','2012','2012','2012','2012','2012','2017','2013','2017','2017','2017','2017','2017','2017','2017','2017'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.unique(df_col_seg_meta['releaseYear'].values))\n",
    "print(len(np.unique(df_col_seg_meta['releaseYear'].values)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "i = 0\n",
    "for val in df_col_seg_meta:\n",
    "    print(i, val)\n",
    "    i += 1\n",
    "    \n",
    "print('\\n', \"Total # of features:\", str(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Y-labels: usHtsDescription\n",
    "# y_label = pd.concat([df_col_seg_meta.iloc[:, 0], df_col_seg_meta.iloc[:, 424]], axis=1)  # gender; primaryCategory\n",
    "# label_no = len(np.unique(y_label.iloc[:, 1].values))\n",
    "\n",
    "\n",
    "## Y-labels: maxResell_premium\n",
    "# y_label = pd.concat([df_maxResell_premium.iloc[:, 2], df_maxResell_premium.iloc[:, 0]], axis=1)\n",
    "# print(y_label.head())\n",
    "\n",
    "\n",
    "## Y-labels: df_bin_premium\n",
    "y_label = pd.concat([df_bin_premium.iloc[:, 2], df_bin_premium.iloc[:, 4]], axis=1)\n",
    "label_no = len(np.unique(y_label.iloc[:, 1].values)); print(label_no)\n",
    "\n",
    "\n",
    "## Y-labels: gender\n",
    "# y_label = pd.concat([df_col_seg_meta.iloc[:, 0], df_col_seg_meta.iloc[:, 420]], axis=1)\n",
    "# label_no = len(np.unique(y_label.iloc[:, 1].values)); print(label_no)\n",
    "\n",
    "\n",
    "# Features\n",
    "color_par = pd.concat([df_col_seg_meta.iloc[:, 0], df_col_seg_meta.iloc[:, 509:521]], axis=1)  # Dist. parameter (Total 12 dimensions) == 509 ~ 520\n",
    "color_ent = pd.concat([df_col_seg_meta.iloc[:, 0], df_col_seg_meta.iloc[:, 521:528]], axis=1)  # Color Entropy (7D) == 521 ~ 527\n",
    "color_seg = pd.concat([df_col_seg_meta.iloc[:, 0], df_col_seg_meta.iloc[:, 528:533]], axis=1)  # Segmentation (5D) == 528 ~ 532\n",
    "color_hst = pd.concat([df_col_seg_meta.iloc[:, 0], df_col_seg_meta.iloc[:, 533:917]], axis=1)  # Color Histogram (128 bin, 384D) == 533 ~ 916"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_label.loc[y_label['gender']=='men','gender'] = 0\n",
    "y_label.loc[y_label['gender']=='women','gender'] = 1\n",
    "y_label.loc[y_label['gender']=='child','gender'] = 2\n",
    "y_label.loc[y_label['gender']=='preschool','gender'] = 3\n",
    "y_label.loc[y_label['gender']=='toddler','gender'] = 4\n",
    "\n",
    "# men          3000 => 0\n",
    "# women        2344 => 1\n",
    "# child        1460 => 2\n",
    "# preschool     420 => 3\n",
    "# toddler       340 => 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_label.loc[y_label['bin_premium']=='premium_lower','bin_premium'] = 0  # Low premium: 0\n",
    "y_label.loc[y_label['bin_premium']=='premium_upper','bin_premium'] = 1  # High premium: 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(label_no)\n",
    "print(np.unique(y_label['primaryCategory'].values))\n",
    "y_label.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_label = {}\n",
    "\n",
    "for i in range(0,label_no):\n",
    "    dict_label[i] = np.unique(y_label['primaryCategory'].values)[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_label.loc[y_label['primaryCategory']=='Air Force','primaryCategory'] = 0  # Air Force: 0\n",
    "y_label.loc[y_label['primaryCategory']=='Air Jordan','primaryCategory'] = 1  # Air Jordan: 1\n",
    "y_label.loc[y_label['primaryCategory']=='Air Max','primaryCategory'] = 2  # Air Max: 2\n",
    "y_label.loc[y_label['primaryCategory']=='Kobe','primaryCategory'] = 3  # Kobe: 3\n",
    "y_label.loc[y_label['primaryCategory']=='LeBron','primaryCategory'] = 4  # LeBron: 4\n",
    "y_label.loc[y_label['primaryCategory']=='Nike Basketball','primaryCategory'] = 5  # Nike Basketball: 5\n",
    "y_label.loc[y_label['primaryCategory']=='Nike SB','primaryCategory'] = 6  # Nike SB: 6\n",
    "y_label.loc[y_label['primaryCategory']=='adidas','primaryCategory'] = 7  # adidas: 7\n",
    "\n",
    "np.unique(y_label['primaryCategory'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Make the total dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_shape_only = df_shape_only.rename(columns={'modelId': 'image_fileName'})\n",
    "y_label = y_label.rename(columns={'modelId': 'image_fileName'})\n",
    "\n",
    "df_shape_total = pd.merge(df_shape_only, y_label, on=\"image_fileName\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_shape_total.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Extract color features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_par_total = pd.merge(color_par, y_label, on=\"image_fileName\")\n",
    "color_ent_total = pd.merge(color_ent, y_label, on=\"image_fileName\")\n",
    "color_seg_total = pd.merge(color_seg, y_label, on=\"image_fileName\")\n",
    "color_hst_total = pd.merge(color_hst, y_label, on=\"image_fileName\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_concat_col_seg  = pd.merge(color_ent_total, color_seg_total, on=\"image_fileName\")  # color_hst_total; color_ent_total\n",
    "del df_concat_col_seg['bin_premium_x']  # gender_x; primaryCategory_x; bin_premium_x; gender_x; inflated_profit_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_concat_col_seg.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_concat_col_shape  = pd.merge(color_ent_total, df_shape_total, on=\"image_fileName\")  # color_hst_total; color_ent_total\n",
    "del df_concat_col_shape['bin_premium_x']  # gender_x; primaryCategory_x; bin_premium_x; gender_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_concat_col_shape.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_concat_shape_seg  = pd.merge(df_shape_total, color_seg_total, on=\"image_fileName\")\n",
    "del df_concat_shape_seg['bin_premium_x']  # gender_x; primaryCategory_x; bin_premium_x; gender_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_concat_shape_seg.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_concat_col_shape_seg  = pd.merge(df_concat_col_shape, color_seg_total, on=\"image_fileName\")\n",
    "del df_concat_col_shape_seg['bin_premium_y']  # gender_y; primaryCategory_y; bin_premium_y; gender_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_concat_col_shape_seg.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training: Regression & XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df_name(df):\n",
    "    name =[x for x in globals() if globals()[x] is df][0]\n",
    "    return name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifying_labels_reg(clf_type, feature_type, loss_term):\n",
    "    if clf_type == 'binary':\n",
    "        pass\n",
    "    elif clf_type == 'multiclass':\n",
    "        model = LogisticRegression(C=1e9, multi_class='multinomial', solver='newton-cg', class_weight='balanced')\n",
    "        pass\n",
    "\n",
    "    average_str = 'weighted'\n",
    "    avg_scores = []; f1_scores = []; auc_scores = []; rmse_scores = []\n",
    "    cof_matricies_test = []; cof_matricies_pred = []; folds_stats_df = pd.DataFrame()\n",
    "        \n",
    "    # split data into train and test sets\n",
    "    seed = 7; test_size = 0.20; val_size = 0.25  # 0.25 x 0.80 = 0.20    \n",
    "    X_train, X_test, yy_train, yy_test = train_test_split(feature_type.iloc[:, 1:-1].astype(\"float64\"), feature_type.iloc[:, -1], test_size=test_size, random_state=seed)\n",
    "    X_train, X_val, yy_train, yy_val = train_test_split(X_train, yy_train, test_size=val_size, random_state=seed)\n",
    "    print(X_train.shape); print(X_val.shape); print(X_test.shape)\n",
    "\n",
    "    # encode string class values as integers\n",
    "    label_encoder = LabelEncoder()\n",
    "    label_encoder = label_encoder.fit(yy_train)\n",
    "    y_train = label_encoder.transform(yy_train)\n",
    "    print(\"y_train shape:: \", y_train.shape)    \n",
    "\n",
    "    label_encoder = LabelEncoder()\n",
    "    label_encoder = label_encoder.fit(yy_val)\n",
    "    y_val = label_encoder.transform(yy_val)\n",
    "    print(\"y_validation shape:: \", y_val.shape)\n",
    "        \n",
    "    label_encoder = LabelEncoder()\n",
    "    label_encoder = label_encoder.fit(yy_test)\n",
    "    y_test = label_encoder.transform(yy_test)\n",
    "    print(\"y_test shape:: \", y_test.shape)    \n",
    "    \n",
    "    val_set = [(X_train, y_train), (X_val, y_val)]\n",
    "    model.fit(X_train, y_train)\n",
    "    pyplot.show()        \n",
    "    \n",
    "    print(\"====================\")\n",
    "    print(\"Fitted model:\", model)\n",
    "    print(\"====================\")\n",
    "    \n",
    "    # make predictions for test data:\n",
    "    y_pred = model.predict(X_test)\n",
    "    predictions = [round(value) for value in y_pred]\n",
    "    # y_preds_probs = clf.predict_proba(X_test)\n",
    "    \n",
    "    '''\n",
    "    # retrieve performance metrics\n",
    "    results = model.evals_result()\n",
    "    epochs = len(results['validation_0'][loss_term])\n",
    "    x_axis = range(0, epochs)\n",
    "    \n",
    "    # plot log loss\n",
    "    fig, ax = pyplot.subplots()\n",
    "    ax.plot(x_axis, results['validation_0'][loss_term], label='Train')\n",
    "    ax.plot(x_axis, results['validation_1'][loss_term], label='Validation')\n",
    "    ax.legend()\n",
    "    pyplot.ylabel('Log Loss')\n",
    "    pyplot.title('XGBoost Log Loss')\n",
    "    pyplot.show()\n",
    "    '''\n",
    "        \n",
    "    # evaluate predictions:\n",
    "    accuracy = accuracy_score(y_test, predictions)\n",
    "    print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))\n",
    "    # r2 = r2_score(y_test, y_pred)\n",
    "    # r2_adj =1- (1-r2)*(len(y_pred)-1)/(len(y_pred)-(len(model.coef_)+1))\n",
    "    cnf_matrix = confusion_matrix(y_test, predictions)\n",
    "    accuracy = accuracy_score(y_test, predictions)\n",
    "    cohen_kappa = cohen_kappa_score(y_test, predictions)\n",
    "    \n",
    "    for k in y_test: cof_matricies_test.append(k)\n",
    "    for i in predictions: cof_matricies_pred.append(i)\n",
    "    f1score_ = f1_score(y_test, predictions, average=average_str)\n",
    "\n",
    "    counter = 1\n",
    "    folds_stats_df.at[counter, 'accuracy'] = accuracy_score(y_test, predictions)\n",
    "    folds_stats_df.at[counter, 'precision'] = precision_score(y_test, predictions, average=average_str)\n",
    "    folds_stats_df.at[counter, 'recall'] = recall_score(y_test, predictions, average=average_str)\n",
    "    folds_stats_df.at[counter, 'f1_score'] = f1_score(y_test, predictions, average=average_str)\n",
    "    folds_stats_df.at[counter, 'cohen_kappa'] = cohen_kappa_score(y_test, predictions)\n",
    "    \n",
    "    print(\"[Test] Unique labels:\", np.unique(np.array(y_test)))\n",
    "    print(\"[Pred] Unique labels:\",np.unique(np.array(predictions)))\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, predictions))\n",
    "    print(\"RMSE: %f\" % (rmse))\n",
    "    print(folds_stats_df)\n",
    "    print(\"====================\")\n",
    "\n",
    "    try:        \n",
    "        num_y_test = np.unique(np.array(y_test), axis=0)\n",
    "        num_y_test = num_y_test.shape[0]\n",
    "        encoding_y_test = np.eye(num_y_test)[np.array(y_test)]\n",
    "        num_predictions = np.unique(np.array(predictions), axis=0)\n",
    "        num_predictions = num_predictions.shape[0]\n",
    "        encoding_predictions = np.eye(num_predictions)[np.array(predictions)]        \n",
    "        \n",
    "        # auc_ = roc_auc_score(y_test, predictions, average=average_str)  # for binary_class\n",
    "        auc_ = roc_auc_score(encoding_y_test, encoding_predictions, multi_class='ovr')  # for multi_class: 'ovo' or 'ovr'\n",
    "        folds_stats_df.at[counter, 'auc'] = auc_\n",
    "        auc_scores.append(auc_)\n",
    "\n",
    "    except ValueError as e:\n",
    "        logging.error(e)\n",
    "        pass\n",
    "\n",
    "    counter += 1\n",
    "\n",
    "    avg_scores.append(accuracy)\n",
    "    f1_scores.append(f1score_)\n",
    "    rmse_scores.append(rmse)\n",
    "\n",
    "    cof_matricies_test = pd.Series(cof_matricies_test)\n",
    "    cof_matricies_pred = np.asarray(cof_matricies_pred)\n",
    "    overall_confusion_matrix = pd.crosstab(cof_matricies_test, cof_matricies_pred, rownames=['True'], colnames=['Predicted'], margins=True)\n",
    "    target_feature = get_df_name(feature_type)\n",
    "    \n",
    "    print(\"\\n\")\n",
    "    print(f\"Feature type: {target_feature} (see below table)\")\n",
    "    print(classification_report(cof_matricies_test, cof_matricies_pred, digits=3))\n",
    "    print(avg_scores)\n",
    "    print(\"AVerage Accuray: %f\" % np.mean(avg_scores))\n",
    "    print(\"AVerage F1: %f\" % np.mean(f1_scores))\n",
    "    print(\"AVerage AUC: %f\" % np.mean(auc_scores))\n",
    "    print(\"AVerage RMSE: %f\" % np.mean(rmse_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifying_labels_XGB(clf_type, feature_type, loss_term):\n",
    "    if clf_type == 'binary':\n",
    "        # model = xgb.XGBRegressor(objective ='binary:logistic', colsample_bytree = 0.3, learning_rate = 0.1, max_depth = 5, alpha = 10, n_estimators = 10)\n",
    "        # model = RandomForestClassifier(n_estimators=100, oob_score=True, random_state=123456)\n",
    "        # model = LogisticRegression(C=1e9, solver='liblinear', class_weight='balanced')\n",
    "        pass\n",
    "    elif clf_type == 'multiclass':\n",
    "        model = xgb.XGBRegressor(objective ='multi:softmax', colsample_bytree = 0.3, learning_rate = 0.05, max_depth = 5, alpha = 10, n_jobs=50, n_estimators = 100, num_class = label_no)\n",
    "        #model = RandomForestClassifier(n_estimators=100, oob_score=True, random_state=123456)\n",
    "        #model = LogisticRegression(C=1e9, multi_class='multinomial', solver='newton-cg', class_weight='balanced')\n",
    "        pass\n",
    "\n",
    "    average_str = 'weighted'\n",
    "    avg_scores = []; f1_scores = []; auc_scores = []; rmse_scores = []\n",
    "    cof_matricies_test = []; cof_matricies_pred = []; folds_stats_df = pd.DataFrame()\n",
    "        \n",
    "    # split data into train and test sets\n",
    "    seed = 7; test_size = 0.20; val_size = 0.25  # 0.25 x 0.80 = 0.20    \n",
    "    X_train, X_test, yy_train, yy_test = train_test_split(feature_type.iloc[:, 1:-1].astype(\"float64\"), feature_type.iloc[:, -1], test_size=test_size, random_state=seed)\n",
    "    X_train, X_val, yy_train, yy_val = train_test_split(X_train, yy_train, test_size=val_size, random_state=seed)\n",
    "    print(\"X_train shape:\",X_train.shape); print(\"X_validation shape:\",X_val.shape); print(\"X_test shape:\",X_test.shape)\n",
    "\n",
    "    # encode string class values as integers\n",
    "    label_encoder = LabelEncoder()\n",
    "    label_encoder = label_encoder.fit(yy_train)\n",
    "    y_train = label_encoder.transform(yy_train)\n",
    "    print(\"y_train shape:\", y_train.shape)    \n",
    "\n",
    "    label_encoder = LabelEncoder()\n",
    "    label_encoder = label_encoder.fit(yy_val)\n",
    "    y_val = label_encoder.transform(yy_val)\n",
    "    print(\"y_validation shape:\", y_val.shape)\n",
    "        \n",
    "    label_encoder = LabelEncoder()\n",
    "    label_encoder = label_encoder.fit(yy_test)\n",
    "    y_test = label_encoder.transform(yy_test)\n",
    "    print(\"y_test shape:\", y_test.shape)\n",
    "    \n",
    "    list_original_label = []\n",
    "    for k in range(0, len(np.unique(np.array(y_test)))):\n",
    "        list_original_label.append(dict_label[k])\n",
    "        \n",
    "    val_set = [(X_train, y_train), (X_val, y_val)]\n",
    "    model.fit(X_train, y_train, early_stopping_rounds=5, eval_metric=loss_term, eval_set=val_set, verbose=False)\n",
    "\n",
    "    try:\n",
    "        plot_importance(model)\n",
    "        pyplot.show()\n",
    "        \n",
    "    except ValueError as e:\n",
    "        logging.error(e)\n",
    "        pass\n",
    "    \n",
    "    print(\"====================\")\n",
    "    print(\"Fitted model:\", model)\n",
    "    print(\"====================\")\n",
    "    \n",
    "    # make predictions for test data:\n",
    "    y_pred = model.predict(X_test)\n",
    "    predictions = [round(value) for value in y_pred]\n",
    "    # y_preds_probs = clf.predict_proba(X_test)\n",
    "    \n",
    "    # retrieve performance metrics\n",
    "    results = model.evals_result()\n",
    "    epochs = len(results['validation_0'][loss_term])\n",
    "    x_axis = range(0, epochs)\n",
    "    \n",
    "    # plot log loss\n",
    "    fig, ax = pyplot.subplots()\n",
    "    ax.plot(x_axis, results['validation_0'][loss_term], label='Train')\n",
    "    ax.plot(x_axis, results['validation_1'][loss_term], label='Validation')\n",
    "    ax.legend()\n",
    "    pyplot.ylabel('Log Loss')\n",
    "    pyplot.title('XGBoost Log Loss')\n",
    "    pyplot.show()\n",
    "        \n",
    "    # evaluate predictions:\n",
    "    accuracy = accuracy_score(y_test, predictions)\n",
    "    print(f\"No. of Epochs: {len(x_axis)}\")\n",
    "    print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))\n",
    "    # r2 = r2_score(y_test, y_pred)\n",
    "    # r2_adj =1- (1-r2)*(len(y_pred)-1)/(len(y_pred)-(len(model.coef_)+1))\n",
    "    cnf_matrix = confusion_matrix(y_test, predictions)\n",
    "    accuracy = accuracy_score(y_test, predictions)\n",
    "    cohen_kappa = cohen_kappa_score(y_test, predictions)\n",
    "    \n",
    "    for k in y_test: cof_matricies_test.append(k)\n",
    "    for i in predictions: cof_matricies_pred.append(i)\n",
    "    f1score_ = f1_score(y_test, predictions, average=average_str)\n",
    "\n",
    "    counter = 1\n",
    "    folds_stats_df.at[counter, 'accuracy'] = accuracy_score(y_test, predictions)\n",
    "    folds_stats_df.at[counter, 'precision'] = precision_score(y_test, predictions, average=average_str)\n",
    "    folds_stats_df.at[counter, 'recall'] = recall_score(y_test, predictions, average=average_str)\n",
    "    folds_stats_df.at[counter, 'f1_score'] = f1_score(y_test, predictions, average=average_str)\n",
    "    folds_stats_df.at[counter, 'cohen_kappa'] = cohen_kappa_score(y_test, predictions)   \n",
    "    \n",
    "    print(\"[Test] Unique labels original:\", np.unique(list_original_label))\n",
    "    print(\"[Test] Unique labels:\", np.unique(np.array(y_test)))\n",
    "    print(\"[Pred] Unique labels:\", np.unique(np.array(predictions)))\n",
    "    print(cnf_matrix, '\\n')\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, predictions))\n",
    "    print(folds_stats_df)\n",
    "    print(\"RMSE: %f\" % (rmse))\n",
    "\n",
    "    try:        \n",
    "        num_y_test = np.unique(np.array(y_test), axis=0)\n",
    "        num_y_test = num_y_test.shape[0]\n",
    "        encoding_y_test = np.eye(num_y_test)[np.array(y_test)]\n",
    "        num_predictions = np.unique(np.array(predictions), axis=0)\n",
    "        num_predictions = num_predictions.shape[0]\n",
    "        encoding_predictions = np.eye(num_predictions)[np.array(predictions)]        \n",
    "        \n",
    "        # auc_ = roc_auc_score(y_test, predictions, average=average_str)  # for binary_class\n",
    "        auc_ = roc_auc_score(encoding_y_test, encoding_predictions, multi_class='ovr')  # for multi_class: 'ovo' or 'ovr'\n",
    "        folds_stats_df.at[counter, 'auc'] = auc_\n",
    "        auc_scores.append(auc_)\n",
    "\n",
    "    except IndexError as e:\n",
    "        logging.error(e)\n",
    "        pass\n",
    "\n",
    "    counter += 1\n",
    "\n",
    "    avg_scores.append(accuracy)\n",
    "    f1_scores.append(f1score_)\n",
    "    rmse_scores.append(rmse)\n",
    "\n",
    "    cof_matricies_test = pd.Series(cof_matricies_test)\n",
    "    cof_matricies_pred = np.asarray(cof_matricies_pred)\n",
    "    overall_confusion_matrix = pd.crosstab(cof_matricies_test, cof_matricies_pred, rownames=['True'], colnames=['Predicted'], margins=True)\n",
    "    target_feature = get_df_name(feature_type)\n",
    "\n",
    "    print(\"\\n\")\n",
    "    print(f\"Feature type: {target_feature} (see below table)\")\n",
    "    print(classification_report(cof_matricies_test, cof_matricies_pred, digits=3))\n",
    "    print(\"Average Accuray: %.3f\" % np.around(np.mean(avg_scores), decimals=3))\n",
    "    print(\"Average F1: %.3f\" % np.around(np.mean(f1_scores), decimals=3))\n",
    "    print(\"Average AUC: %.3f\" % np.around(np.mean(auc_scores), decimals=3))\n",
    "    print(\"Average RMSE: %.3f\" % np.around(np.mean(rmse_scores), decimals=3))\n",
    "    \n",
    "    # print(frame_feature_importance.T.mean(axis=0))\n",
    "    # print(np.std(avg_scores))\n",
    "    # print('Overall Accuracy:', accuracy_score(cof_matricies_test, cof_matricies_pred))\n",
    "    # print('Overall Precision:', precision_score(cof_matricies_test, cof_matricies_pred, average=average_str))\n",
    "    # print('Overall Recall:', recall_score(cof_matricies_test, cof_matricies_pred, average=average_str))\n",
    "    # print('Overall F1-score:', f1_score(cof_matricies_test, cof_matricies_pred, average=average_str))\n",
    "    # print('Overall AUC score:', roc_auc_score(cof_matricies_test, cof_matricies_pred, average='macro'))\n",
    "    # print('Overall AUC score:', multiclass_roc_auc_score(cof_matricies_test, cof_matricies_pred))\n",
    "    # cnf_matrix = confusion_matrix(cof_matricies_test, cof_matricies_pred); print(cnf_matrix)\n",
    "    # print(folds_stats_df['accuracy'].mean())\n",
    "    # print(r2, r2_adj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Execution Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_Classification():\n",
    "    clf_type = 'multiclass'  # = 'binary'\n",
    "    loss_term = 'mlogloss'\n",
    "    feature_type = df_shape_total\n",
    "    classifying_labels_reg(clf_type, feature_type, loss_term)\n",
    "    #classifying_labels_XGB(clf_type, feature_type, loss_term)\n",
    "\n",
    "# Solo: color_par_total; color_ent_total; color_seg_total; color_hst_total; df_shape_total    \n",
    "# Concat: df_concat_col_seg; df_concat_col_shape; df_concat_shape_seg; df_concat_col_shape_seg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    do_Classification()\n",
    "    print('\\n'+str(\"***** All successfully done *****\")+'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training: Multi-Layer Perceptron (Classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "from sklearn.datasets import load_wine\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solo: color_par_total; color_ent_total; color_hst_total; color_seg_total; df_shape_total    \n",
    "# Concat: df_concat_col_seg; df_concat_col_shape; df_concat_shape_seg; df_concat_col_shape_seg\n",
    "\n",
    "seed = 7\n",
    "test_size = 0.20\n",
    "target_dataframe = color_seg_total\n",
    "\n",
    "train_XX, test_XX, train_YY, test_YY = train_test_split(target_dataframe.iloc[:,1: -1].astype(\"float64\"), \n",
    "                                                        target_dataframe.iloc[:, -1].astype(\"int64\"),\n",
    "                                                        test_size=test_size, random_state=seed)\n",
    "\n",
    "train_X = train_XX.to_numpy()  # 넘파이 배열로 만들기\n",
    "test_X  = test_XX.to_numpy()   # 넘파이 배열로 만들기\n",
    "train_Y = train_YY.to_numpy().reshape((-1,1))  # 데이터프레임 형태의 타겟값을 넘파이 배열로 만들기\n",
    "test_Y = test_YY.to_numpy().reshape((-1,1))    # 데이터프레임 형태의 타겟값을 넘파이 배열로 만들기\n",
    "\n",
    "# 데이터를 텐서 형태로 변환\n",
    "train_X = torch.from_numpy(train_X).float()\n",
    "train_Y = torch.from_numpy(train_Y).long()\n",
    "\n",
    "test_X = torch.from_numpy(test_X).float()\n",
    "test_Y = torch.from_numpy(test_Y).float()\n",
    "\n",
    "trainset = TensorDataset(train_X, train_Y)\n",
    "testset = TensorDataset(test_X, test_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(trainset[2])  # Just peep one example\n",
    "# classes = ('Air Force','Air Jordan','Air Max','Kobe','LeBron','Nike Basketball','Nike SB','adidas')\n",
    "classes = ('Low Premium','High Premium')\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(trainset, batch_size=4, shuffle=True, num_workers=2, drop_last=True)\n",
    "test_loader  = torch.utils.data.DataLoader(testset, batch_size=4, shuffle=False, num_workers=2, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_X.shape)\n",
    "print(train_Y.shape)\n",
    "print(test_X.shape)\n",
    "print(test_Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 12005/4  # batch_no=4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "#         self.fc1 = nn.Linear(524, 96)  # reference\n",
    "#         self.fc2 = nn.Linear(96, 96)\n",
    "#         self.fc3 = nn.Linear(96, 96)\n",
    "#         self.fc4 = nn.Linear(96, 96)\n",
    "#         self.fc5 = nn.Linear(96, 96)\n",
    "#         self.fc6 = nn.Linear(96, 8)    # 8; 2\n",
    "\n",
    "#         self.fc1 = nn.Linear(12, 7)\n",
    "#         self.fc2 = nn.Linear(7, 7)\n",
    "#         self.fc3 = nn.Linear(7, 7)\n",
    "#         self.fc4 = nn.Linear(7, 2)\n",
    "\n",
    "#         self.fc1 = nn.Linear(7, 4)\n",
    "#         self.fc2 = nn.Linear(4, 4)\n",
    "#         self.fc3 = nn.Linear(4, 4)\n",
    "#         self.fc4 = nn.Linear(4, 2)\n",
    "\n",
    "        self.fc1 = nn.Linear(5, 3)\n",
    "        self.fc2 = nn.Linear(3, 3)\n",
    "        self.fc3 = nn.Linear(3, 3)\n",
    "        self.fc4 = nn.Linear(3, 2)\n",
    "\n",
    "#         self.fc1 = nn.Linear(384, 96)  # 384; 512\n",
    "#         self.fc2 = nn.Linear(96, 96)\n",
    "#         self.fc3 = nn.Linear(96, 96)\n",
    "#         self.fc4 = nn.Linear(96, 96)\n",
    "#         self.fc5 = nn.Linear(96, 96)\n",
    "#         self.fc6 = nn.Linear(96, 2)\n",
    "\n",
    "#         self.fc1 = nn.Linear(1536, 96)\n",
    "#         self.fc2 = nn.Linear(96, 96)\n",
    "#         self.fc3 = nn.Linear(96, 96)\n",
    "#         self.fc4 = nn.Linear(96, 96)\n",
    "#         self.fc5 = nn.Linear(96, 96)\n",
    "#         self.fc6 = nn.Linear(96, 96)\n",
    "#         self.fc7 = nn.Linear(96, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "#         x = torch.flatten(x, 1)  # 배치를 제외한 모든 차원을 평탄화(flatten)\n",
    "\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = self.fc4(x)        \n",
    "\n",
    "#         x = F.relu(self.fc1(x))\n",
    "#         x = F.relu(self.fc2(x))\n",
    "#         x = F.relu(self.fc3(x))\n",
    "#         x = F.relu(self.fc4(x))\n",
    "#         x = F.relu(self.fc5(x))\n",
    "#         #x = F.relu(self.fc6(x))\n",
    "#         x = self.fc6(x)\n",
    "                \n",
    "#       return F.log_softmax(x)  # nn.CrossEntropyLoss() 에서 같은 작업 수행\n",
    "        return x\n",
    "\n",
    "model = Net()  # It should be run for every new data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 오차함수\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# 최적화 담당\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "# 학습 실시\n",
    "list_loss = []\n",
    "for epoch in range(300):  # 데이터셋 학습 N차례 (e.g., 300회) 반복\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        # [inputs, labels]의 목록인 data로부터 입력을 받은 후,\n",
    "        inputs, labels = data\n",
    "\n",
    "        # 경사 초기화: 변화도(Gradient) 매개변수를 0으로 만들고,\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # 순전파 + 역전파 + 최적화를 한 후,\n",
    "        outputs = model(inputs)            # 순전파\n",
    "        labels = labels.squeeze_()         # https://stackoverflow.com/questions/49206550/pytorch-error-multi-target-not-supported-in-crossentropyloss/49209628\n",
    "        loss = criterion(outputs, labels)  # 오차\n",
    "        loss.backward()                    # 역전파 계산\n",
    "        optimizer.step()                   # 가중치 업데이트\n",
    "\n",
    "        running_loss += loss.item()        # 총 오차 업데이트\n",
    "        \n",
    "        # 통계 출력.\n",
    "        report_tick = 10\n",
    "        if i % report_tick == report_tick-1:   # print every \"report_tick\" mini-batches\n",
    "            print('[%d, %5d] loss: %.5f' %\n",
    "                 (epoch + 1, i + 1, running_loss / report_tick))\n",
    "            list_loss.append(running_loss)\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('\\n','Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(list_loss)\n",
    "plt.title('Loss')\n",
    "plt.xlabel('1K Mini-batch')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 테스트 데이터를 집어 넣는다.\n",
    "test_x, test_y = Variable(test_X), Variable(test_Y)\n",
    "\n",
    "# 테스트 데이터를 집어 넣어서 학습 시킨 다음, max 값(확률이 더 높은 값)을 출력한다.\n",
    "result = torch.max(model(test_x).data, 1)[1]\n",
    "\n",
    "# 정확도 계산\n",
    "accuracy = sum(test_y.data.numpy() == result.numpy().reshape((-1,1))) / len(test_y.data.numpy())\n",
    "print(accuracy.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html\n",
    "\n",
    "print(f1_score(test_y.data.numpy(), result.numpy().reshape((-1,1)), average='macro'))\n",
    "print(f1_score(test_y.data.numpy(), result.numpy().reshape((-1,1)), average='micro'))\n",
    "print(f1_score(test_y.data.numpy(), result.numpy().reshape((-1,1)), average='weighted'))  # Using this one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import cohen_kappa_score\n",
    "\n",
    "cohen_kappa_score(test_y.data.numpy(), result.numpy().reshape((-1,1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.metrics.precision_score.html\n",
    "\n",
    "print(precision_score(test_y.data.numpy(), result.numpy().reshape((-1,1)), average='macro'))\n",
    "print(precision_score(test_y.data.numpy(), result.numpy().reshape((-1,1)), average='micro'))\n",
    "print(precision_score(test_y.data.numpy(), result.numpy().reshape((-1,1)), average='weighted'))  # Using this one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import recall_score\n",
    "\n",
    "print(recall_score(test_y.data.numpy(), result.numpy().reshape((-1,1)), average='macro'))\n",
    "print(recall_score(test_y.data.numpy(), result.numpy().reshape((-1,1)), average='micro'))\n",
    "print(recall_score(test_y.data.numpy(), result.numpy().reshape((-1,1)), average='weighted'))  # Using this one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습한 모델 저장\n",
    "\n",
    "PATH = '_results/mlp_total.pth'\n",
    "torch.save(model.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load the saved model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(524, 96)\n",
    "        self.fc2 = nn.Linear(96, 96)\n",
    "        self.fc3 = nn.Linear(96, 96)\n",
    "        self.fc4 = nn.Linear(96, 96)\n",
    "        self.fc5 = nn.Linear(96, 96)\n",
    "        self.fc6 = nn.Linear(96, 8)\n",
    "\n",
    "    def forward(self, x):\n",
    "#       x = torch.flatten(x, 1) # 배치를 제외한 모든 차원을 평탄화(flatten)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = F.relu(self.fc4(x))\n",
    "        x = F.relu(self.fc5(x))\n",
    "\n",
    "        x = self.fc6(x)        \n",
    "#       return F.log_softmax(x)\n",
    "        return x\n",
    "\n",
    "net = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = '_results/mlp_total.pth'  # 저장한 모델 로딩\n",
    "net.load_state_dict(torch.load(PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataiter = iter(test_loader)\n",
    "feats, labels = dataiter.next()\n",
    "outputs = net(feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, predicted = torch.max(outputs, 1)\n",
    "\n",
    "print('Predicted: ', ' '.join('%5s' % classes[predicted[j]] for j in range(4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "# 학습 중이 아니므로, 출력에 대한 변화도를 계산할 필요 X\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        feats, labels = data\n",
    "        \n",
    "        # 신경망에 테스트 데이터를 통과시켜 출력을 계산합니다\n",
    "        outputs = net(feats)\n",
    "        \n",
    "        # 가장 높은 값(energy)를 갖는 분류(class)를 정답으로 선택\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == torch.transpose(labels,0,1)).sum().item()        \n",
    "\n",
    "print('Accuracy of the network on the test datatest: %d %%' % (100 * correct / total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training: Multi-Layer Perceptron (Regressor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# machine learning module\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# ANN module\n",
    "import torch\n",
    "from torch import nn, optim                       # torch 제공 신경망 기술, 손실함수, 최적화를 할 수 있는 함수들을 불러온다.\n",
    "from torch.utils.data import DataLoader, Dataset  # 데이터를 모델에 사용할 수 있게 정리해주는 라이브러리.\n",
    "import torch.nn.functional as F                   # torch 내의 세부적인 기능을 불러옴.\n",
    "\n",
    "# Loss\n",
    "from sklearn.metrics import mean_squared_error    # regression 문제의 모델 성능 측정을 위해서 MSE를 불러온다.\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solo: color_par_total; color_ent_total; color_seg_total; color_hst_total; df_shape_total    \n",
    "# Concat: df_concat_col_seg; df_concat_col_shape; df_concat_shape_seg; df_concat_col_shape_seg\n",
    "\n",
    "target_dataframe = color_hst_total\n",
    "\n",
    "# 데이터를 넘파이 배열로 만들기\n",
    "X = target_dataframe.iloc[:, 1:-1].astype(\"float64\").to_numpy()  # 데이터프레임에서 타겟값 제외하고 넘파이 배열로 만들기\n",
    "Y = target_dataframe.iloc[:, -1].to_numpy().reshape((-1,1))      # 데이터프레임 형태의 타겟값을 넘파이 배열로 만들기\n",
    "\n",
    "# 데이터 스케일링: sklearn 제공 MinMaxScaler => (X-min(X))/(max(X)-min(X)) 계산\n",
    "scaler = MinMaxScaler() \n",
    "scaler.fit(X) \n",
    "X = scaler.transform(X)\n",
    "\n",
    "scaler.fit(Y)\n",
    "Y = scaler.transform(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "for val in target_dataframe:\n",
    "    print(i, val)\n",
    "    i += 1\n",
    "    \n",
    "print('\\n', \"Total # of features:\", str(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch의 Dataset 을 상속.\n",
    "class TensorData(Dataset):\n",
    "\n",
    "    def __init__(self, x_data, y_data):\n",
    "        self.x_data = torch.FloatTensor(x_data)\n",
    "        self.y_data = torch.FloatTensor(y_data)\n",
    "        self.len = self.y_data.shape[0]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "\n",
    "        return self.x_data[index], self.y_data[index] \n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전체 데이터를 학습 데이터와 평가 데이터로 나눈다.\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3)\n",
    "\n",
    "# 학습 데이터, 시험 데이터 배치 형태로 구축하기\n",
    "trainsets = TensorData(X_train, Y_train)\n",
    "trainloader = torch.utils.data.DataLoader(trainsets, batch_size=32, shuffle=True)  # batch_size=4;32;64\n",
    "\n",
    "testsets = TensorData(X_test, Y_test)\n",
    "testloader = torch.utils.data.DataLoader(testsets, batch_size=32, shuffle=False)  # batch_size=4;32;64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X.shape)\n",
    "print(Y.shape)\n",
    "print(X_train.shape)\n",
    "print(Y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 구축: for small dimensions\n",
    "class Regressor(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__() # 모델 연산 정의\n",
    "        self.fc1 = nn.Linear(5, 3, bias=True)\n",
    "        self.fc2 = nn.Linear(3, 3, bias=True)\n",
    "        self.fc3 = nn.Linear(3, 3, bias=True) \n",
    "        self.fc4 = nn.Linear(3, 1, bias=True)\n",
    "        self.dropout = nn.Dropout(0.2) # 연산이 될 때마다 20%의 비율로 랜덤하게 노드를 없앤다.\n",
    "\n",
    "    def forward(self, x): # 모델 연산의 순서를 정의\n",
    "        x = F.relu(self.fc1(x)) # Linear 계산 후 활성화 함수 ReLU를 적용한다.\n",
    "        x = self.dropout(F.relu(self.fc2(x))) # 은닉층2에서 드랍아웃을 적용한다.\n",
    "        x = self.dropout(F.relu(self.fc3(x))) \n",
    "        x = F.relu(self.fc4(x)) # Linear 계산 후 활성화 함수 ReLU를 적용한다.\n",
    "      \n",
    "        return x\n",
    "    \n",
    "## 주의 사항:\n",
    "# 드랍아웃은 과적합(overfitting)을 방지하기 위해 노드의 일부를 배제하고 계산하는 방식이기 때문에 절대로 출력층에 사용해서는 안 된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 구축\n",
    "class Regressor(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__() # 모델 연산 정의\n",
    "        self.fc1 = nn.Linear(X.shape[1], 96, bias=True) # 입력층(524) -> 은닉층1(96)으로 가는 연산\n",
    "        self.fc2 = nn.Linear(96, 96, bias=True) # 은닉층1(96) -> 은닉층2(96)으로 가는 연산\n",
    "        self.fc3 = nn.Linear(96, 96, bias=True) \n",
    "        self.fc4 = nn.Linear(96, 96, bias=True) \n",
    "        self.fc5 = nn.Linear(96, 96, bias=True)         \n",
    "        self.fc6 = nn.Linear(96, 1, bias=True) # 은닉층5(96) -> 출력층(1)으로 가는 연산\n",
    "        self.dropout = nn.Dropout(0.2) # 연산이 될 때마다 20%의 비율로 랜덤하게 노드를 없앤다.\n",
    "\n",
    "    def forward(self, x): # 모델 연산의 순서를 정의\n",
    "        x = F.relu(self.fc1(x)) # Linear 계산 후 활성화 함수 ReLU를 적용한다.\n",
    "        x = self.dropout(F.relu(self.fc2(x))) # 은닉층2에서 드랍아웃을 적용한다.(즉, 30개의 20%인 6개의 노드가 계산에서 제외된다.)\n",
    "        x = self.dropout(F.relu(self.fc3(x))) \n",
    "        x = self.dropout(F.relu(self.fc4(x))) \n",
    "        x = self.dropout(F.relu(self.fc5(x)))\n",
    "        x = F.relu(self.fc6(x)) # Linear 계산 후 활성화 함수 ReLU를 적용한다.\n",
    "      \n",
    "        return x\n",
    "    \n",
    "## 주의 사항:\n",
    "# 드랍아웃은 과적합(overfitting)을 방지하기 위해 노드의 일부를 배제하고 계산하는 방식이기 때문에 절대로 출력층에 사용해서는 안 된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Regressor()\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-7)  # weight_decay: L2 norm 정규화에서 사용하는 penalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "loss_ = [] # loss를 저장할 리스트.\n",
    "n = len(trainloader)\n",
    "\n",
    "for epoch in range(300):  # 300; 400\n",
    "    running_loss = 0.0    # 한 에폭이 돌 때 그안에서 배치마다 loss가 나온다. \n",
    "                          # 즉 한번 학습할 때 그렇게 쪼개지면서 loss가 다 나오니 MSE를 구하기 위해서 사용한다.\n",
    "\n",
    "    for i, data in enumerate(trainloader, 0): # 무작위로 섞인 32개의 데이터가 담긴 배치가 하나씩 들어온다.\n",
    "    \n",
    "        inputs, values = data # data에는 X, Y가 들어있다.\n",
    "        optimizer.zero_grad() # 최적화 초기화.\n",
    "\n",
    "        outputs = model(inputs) # 모델에 입력값을 넣어 예측값을 산출한다.\n",
    "        loss = criterion(outputs, values) # 손실함수를 계산. error 계산.\n",
    "        loss.backward() # 손실 함수를 기준으로 역전파를 설정한다.\n",
    "        optimizer.step() # 역전파를 진행하고 가중치를 업데이트한다.\n",
    "\n",
    "        running_loss += loss.item() # 총 오차 업데이트: epoch 마다 평균 loss를 계산하기 위해 배치 loss를 더한다.\n",
    "        \n",
    "        # 통계 출력:\n",
    "        report_tick = 10\n",
    "        if i % report_tick == report_tick-1:   # print every 10 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                 (epoch + 1, i + 1, running_loss / report_tick))\n",
    "  \n",
    "    loss_.append(running_loss/n) # MSE(Mean Squared Error) 계산\n",
    "\n",
    "print('\\n','Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(loss_)\n",
    "plt.title('Loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation(dataloader):\n",
    "\n",
    "    predictions = torch.tensor([], dtype=torch.float) # 예측값을 저장하는 텐서.\n",
    "    actual = torch.tensor([], dtype=torch.float) # 실제값을 저장하는 텐서.\n",
    "\n",
    "    with torch.no_grad():\n",
    "        model.eval() # 평가를 할 땐 반드시 eval()을 사용해야 한다.\n",
    "\n",
    "        for data in dataloader:\n",
    "            inputs, values = data\n",
    "            outputs = model(inputs)\n",
    "\n",
    "            predictions = torch.cat((predictions, outputs), 0) # cat함수를 통해 예측값을 누적.\n",
    "            actual = torch.cat((actual, values), 0) # cat함수를 통해 실제값을 누적.\n",
    "\n",
    "    predictions = predictions.numpy() # 넘파이 배열로 변경.\n",
    "    actual = actual.numpy() # 넘파이 배열로 변경.\n",
    "    rmse = np.sqrt(mean_squared_error(predictions, actual)) # sklearn을 이용해 RMSE를 계산.\n",
    "    r_sq_score = r2_score(predictions, actual)\n",
    "    mae = mean_absolute_error(predictions, actual)\n",
    "\n",
    "    return r_sq_score, rmse, mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "\n",
    "train_rmse = evaluation(trainloader)\n",
    "test_rmse = evaluation(testloader)\n",
    "\n",
    "print(f'[Train] R^2, RMSE, MAE:{train_rmse}')\n",
    "print(f'[Test] R^2, RMSE, MAE:{test_rmse}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## buffer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### End."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
