{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pdb\n",
    "import glob\n",
    "import argparse\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.models.resnet import resnet50, resnet18\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from sklearn.cluster import _k_means_fast as _k_means\n",
    "from sklearn.metrics import silhouette_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SneakersX(Dataset):\n",
    "    def __init__(self, data_path='/home/data/sneakers/resized_img/', \n",
    "                 transform_org=None, transform_all=None, transform_shape=None, transform_color=None, \n",
    "                 meta_datapath='/home/data/sneakers/val_sneakers_df.pkl', mode='train'):\n",
    "        \n",
    "        self.meta = pd.read_pickle(meta_datapath)\n",
    "        self.pid = self.meta['pid'].values\n",
    "        image_pids = []\n",
    "        for image_fname in glob.glob(data_path+'*'):\n",
    "            image_pids.append(image_fname.split('/')[-1][:-4])\n",
    "        set_pid, set_img_pid = set(self.pid), set(image_pids)\n",
    "        print(len(set_pid))\n",
    "        print(len(set_img_pid))\n",
    "        \n",
    "        self.pid = list(set_pid.intersection(set_img_pid))\n",
    "        self.img = []\n",
    "        self.data_path = data_path\n",
    "        for pid in self.pid:\n",
    "            img_name = self.data_path+pid+'.jpg'\n",
    "            img = Image.open(img_name)\n",
    "            self.img.append(np.array(img))\n",
    "        \n",
    "        self.transform_all=transform_all\n",
    "        self.transform_shape=transform_shape\n",
    "        self.transform_color=transform_color\n",
    "        self.transform_org=transform_org\n",
    "        if mode=='meta':\n",
    "            self.mode = 'meta'\n",
    "        else:\n",
    "            self.mode = 'train'\n",
    "            \n",
    "    def __getitem__(self,idx):\n",
    "        pid = self.pid[idx]\n",
    "        img = self.img[idx]\n",
    "        img = Image.fromarray(img)\n",
    "        if self.transform_shape and self.transform_color:\n",
    "            pos_org = self.transform_org(img)\n",
    "            pos_all = self.transform_all(img)\n",
    "            pos_shape = self.transform_shape(img)\n",
    "            pos_color = self.transform_color(img)\n",
    "        else:\n",
    "            pos_org,pos_all,pos_shape,pos_color = img,img,img,img\n",
    "            \n",
    "        if self.mode=='train':\n",
    "            return pos_org,pos_all,pos_shape,pos_color\n",
    "        \n",
    "        return pos_org,pid\n",
    "    \n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.pid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [Image Augmentaiton] Dataloader usage\n",
    "train_transform_org = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.4914, 0.4822, 0.4465], [0.2023, 0.1994, 0.2010])])\n",
    "\n",
    "train_transform_all = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(256),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomApply([transforms.ColorJitter(0.4, 0.4, 0.4, 0.1)], p=1), # color augmentation\n",
    "    transforms.RandomGrayscale(p=0.2), # color augmentation\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.4914, 0.4822, 0.4465], [0.2023, 0.1994, 0.2010])])\n",
    "\n",
    "train_transform_shape = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(256),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.4914, 0.4822, 0.4465], [0.2023, 0.1994, 0.2010])])\n",
    "\n",
    "train_transform_color = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.RandomApply([transforms.ColorJitter(0.4, 0.4, 0.4, 0.1)], p=1), # color augmentation\n",
    "    transforms.RandomGrayscale(p=0.2), # color augmentation\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.4914, 0.4822, 0.4465], [0.2023, 0.1994, 0.2010])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = SneakersX(transform_org = train_transform_org, \n",
    "                    transform_all = train_transform_all, \n",
    "                    transform_shape= train_transform_shape,\n",
    "                    transform_color = train_transform_color)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train for one epoch to learn unique features\n",
    "def train(net, data_loader, train_optimizer):\n",
    "    net.train()\n",
    "    total_loss, total_num, train_bar = 0.0, 0, tqdm(data_loader)\n",
    "\n",
    "    for pos_org, pos_all, pos_shape, pos_color in train_bar:\n",
    "        batch_size = pos_org.size(0)\n",
    "        pos_org, pos_all = pos_org.cuda(non_blocking=True), pos_all.cuda(non_blocking=True)\n",
    "        pos_shape, pos_color = pos_shape.cuda(non_blocking=True), pos_color.cuda(non_blocking=True)\n",
    "        \n",
    "        pos_all_pair = torch.cat((pos_org, pos_all))\n",
    "        pos_shape_pair = torch.cat((pos_org, pos_shape))\n",
    "        pos_color_pair = torch.cat((pos_org, pos_color))\n",
    "        \n",
    "        _, out_alls = net(pos_all_pair, query_type=torch.tensor(0).repeat(batch_size * 2).cuda())\n",
    "        _, out_shapes = net(pos_shape_pair, query_type=torch.tensor(1).repeat(batch_size * 2).cuda())\n",
    "        _, out_colors = net(pos_color_pair, query_type=torch.tensor(2).repeat(batch_size * 2).cuda())\n",
    "        \n",
    "        out_org1, out_all = torch.split(out_alls, len(out_alls) // 2)\n",
    "        out_org2, out_shape = torch.split(out_shapes, len(out_shapes) // 2)\n",
    "        out_org3, out_color = torch.split(out_colors, len(out_colors) // 2)\n",
    "               \n",
    "        # all-invariant loss\n",
    "        sim_matrix1 = torch.exp(torch.mm(out_alls, out_alls.t().contiguous()) / temperature)\n",
    "        mask1 = (torch.ones_like(sim_matrix1) - torch.eye(2 * batch_size, device=sim_matrix1.device)).bool()\n",
    "        sim_matrix1 = sim_matrix1.masked_select(mask1).view(2 * batch_size, -1)[:batch_size, :]\n",
    "        pos_org_all = torch.exp(torch.sum(out_org1 * out_all, dim=-1) / temperature)\n",
    "        all_loss = (- torch.log(pos_org_all / sim_matrix1.sum(dim=-1))).mean()\n",
    "        \n",
    "        # shape-invariant loss\n",
    "        sim_matrix2 = torch.exp(torch.mm(out_shapes, out_shapes.t().contiguous()) / temperature)\n",
    "        mask2 = (torch.ones_like(sim_matrix2) - torch.eye(2 * batch_size, device=sim_matrix2.device)).bool()\n",
    "        sim_matrix2 = sim_matrix2.masked_select(mask2).view(2 * batch_size, -1)[:batch_size, :]\n",
    "        pos_org_shape = torch.exp(torch.sum(out_org2 * out_shape, dim=-1) / temperature)\n",
    "        shape_loss = (- torch.log(pos_org_shape / sim_matrix2.sum(dim=-1))).mean()\n",
    "        \n",
    "        # color-invariant loss\n",
    "        sim_matrix3 = torch.exp(torch.mm(out_colors, out_colors.t().contiguous()) / temperature)\n",
    "        mask3 = (torch.ones_like(sim_matrix3) - torch.eye(2 * batch_size, device=sim_matrix3.device)).bool()\n",
    "        sim_matrix3 = sim_matrix3.masked_select(mask3).view(2 * batch_size, -1)[:batch_size, :]\n",
    "        pos_org_shape = torch.exp(torch.sum(out_org3 * out_color, dim=-1) / temperature)\n",
    "        color_loss = (- torch.log(pos_org_shape / sim_matrix3.sum(dim=-1))).mean()\n",
    "        \n",
    "        loss = all_loss + shape_loss + color_loss\n",
    "        train_optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        train_optimizer.step()\n",
    "\n",
    "        total_num += batch_size\n",
    "        total_loss += loss.item() * batch_size\n",
    "        train_bar.set_description('Train Epoch: [{}/{}] Loss: {:.4f}'.format(epoch, epochs, total_loss / total_num))\n",
    "\n",
    "    return total_loss / total_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet18(nn.Module):\n",
    "    def __init__(self, feature_dim=128):\n",
    "        super(ResNet18, self).__init__()\n",
    "\n",
    "        self.f = []\n",
    "        for name, module in resnet18(pretrained=True).named_children():\n",
    "            if not isinstance(module, nn.Linear) and not isinstance(module, nn.MaxPool2d):\n",
    "                self.f.append(module)\n",
    "        # encoder\n",
    "        self.f = nn.Sequential(*self.f)\n",
    "        self.query = nn.Embedding(num_embeddings = 3, embedding_dim = 512, padding_idx = 1)\n",
    "        \n",
    "        # projection head\n",
    "        self.g_all = nn.Sequential(nn.Linear(512, 512, bias=False), nn.BatchNorm1d(512),\n",
    "                               nn.ReLU(inplace=True), nn.Linear(512, feature_dim, bias=True))\n",
    "        \n",
    "        self.g_shape = nn.Sequential(nn.Linear(512, 512, bias=False), nn.BatchNorm1d(512),\n",
    "                               nn.ReLU(inplace=True), nn.Linear(512, feature_dim, bias=True))\n",
    "        \n",
    "        self.g_color = nn.Sequential(nn.Linear(512, 512, bias=False), nn.BatchNorm1d(512),\n",
    "                               nn.ReLU(inplace=True), nn.Linear(512, feature_dim, bias=True))\n",
    "        self.g_list = nn.ModuleList([self.g_all, self.g_shape, self.g_color])\n",
    "\n",
    "        \n",
    "    def forward(self, x, query_type, normalize=True):\n",
    "        x = self.f(x)\n",
    "        org_feature = torch.flatten(x, start_dim=1)\n",
    "        mask = torch.sigmoid(self.query(query_type))\n",
    "        feature = org_feature * mask\n",
    "        out = self.g_list[query_type[0]](feature)\n",
    "        if normalize == False:\n",
    "            return org_feature, feature, F.normalize(out, dim=-1)\n",
    "        \n",
    "        return F.normalize(feature, dim=-1), F.normalize(out, dim=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser(description='Train SimCLR')\n",
    "parser.add_argument('--feature_dim', default=128, type=int, help='Feature dim for latent vector')\n",
    "parser.add_argument('--temperature', default=0.5, type=float, help='Temperature used in softmax')\n",
    "parser.add_argument('--k', default=200, type=int, help='Top k most similar images used to predict the label')\n",
    "parser.add_argument('--batch_size', default=128, type=int, help='Number of images in each mini-batch')\n",
    "parser.add_argument('--epochs', default=500, type=int, help='Number of sweeps over the dataset to train')\n",
    "parser.add_argument('--seed', default=1567010775, type=int, help='random seed')\n",
    "\n",
    "# args parse\n",
    "args = parser.parse_args('')  # settings become default\n",
    "feature_dim, temperature, k = args.feature_dim, args.temperature, args.k\n",
    "batch_size, epochs = args.batch_size, args.epochs\n",
    "\n",
    "# data prepare\n",
    "train_data = dataset\n",
    "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True, num_workers=16, pin_memory=True, drop_last=True)\n",
    "\n",
    "# model setup and optimizer config\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = ResNet18(feature_dim)\n",
    "\n",
    "if torch.cuda.device_count() > 1:\n",
    "    model = nn.DataParallel(model)\n",
    "    model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-6)\n",
    "\n",
    "# training loop\n",
    "save_name_pre = 'preact_looc_{}_{}_{}_{}_{}'.format(feature_dim, temperature, k, batch_size, epochs)\n",
    "if not os.path.exists('results'):\n",
    "    os.mkdir('results')\n",
    "\n",
    "for epoch in range(1, epochs + 1):\n",
    "    train_loss = train(model, train_loader, optimizer)\n",
    "    if epoch==1 or epoch % 50 == 0:\n",
    "        torch.save(model.state_dict(), 'results/epoch{}_{}_model_sneakers_mask.pth'.format(epoch, save_name_pre))\n",
    "    \n",
    "torch.save(model.state_dict(), 'results/final_{}_model_sneakers_mask.pth'.format(save_name_pre))\n",
    "print('\\n', '[END] {}_model_sneakers.pth => The trained has been saved!'.format(save_name_pre))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet_feature_dim = 128\n",
    "PATH = 'results/final_{}_model_sneakers_mask.pth'.format(save_name_pre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# model setup and optimizer config\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = ResNet18(resnet_feature_dim)\n",
    "\n",
    "if torch.cuda.device_count() > 1:\n",
    "    model = nn.DataParallel(model)\n",
    "    model.cuda()\n",
    "\n",
    "model.load_state_dict(torch.load(PATH))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.4914, 0.4822, 0.4465], [0.2023, 0.1994, 0.2010])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testset = SneakersX(transform_org = test_transform, \n",
    "                    transform_all = test_transform, \n",
    "                    transform_shape= test_transform,\n",
    "                    transform_color = test_transform, mode = 'meta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = DataLoader(testset, batch_size=64, shuffle=False, num_workers=16, pin_memory=True, drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "org_list = []\n",
    "feature_all_list = []\n",
    "feature_shape_list = []\n",
    "feature_color_list = []\n",
    "out_all_list = []\n",
    "\n",
    "img_label_dict = {}\n",
    "with torch.no_grad():\n",
    "    for pos_1, meta in tqdm(test_loader):\n",
    "        pos_1 = pos_1.cuda(non_blocking=True)\n",
    "        batch_szsz = pos_1.size(0)\n",
    "        \n",
    "        org_feature_all, feature_all, out_all = model(pos_1, query_type=torch.tensor(0).repeat(batch_szsz).cuda(), normalize=False)\n",
    "        _, feature_shape, out_shape = model(pos_1, query_type=torch.tensor(1).repeat(batch_szsz).cuda(), normalize=False)\n",
    "        _, feature_color, out_color = model(pos_1, query_type=torch.tensor(2).repeat(batch_szsz).cuda(), normalize=False)\n",
    "        out_total = torch.cat((out_all, out_shape, out_color), dim=1)\n",
    "        \n",
    "        org_list.append(org_feature_all)\n",
    "        feature_all_list.append(feature_all)\n",
    "        feature_shape_list.append(feature_shape)\n",
    "        feature_color_list.append(feature_color)\n",
    "        out_all_list.append(out_total)\n",
    "\n",
    "        for label_ in meta:\n",
    "            img_label_dict[i] = label_\n",
    "            i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "org_cat = torch.cat(org_list, dim = 0)\n",
    "feature_all_cat = torch.cat(feature_all_list, dim = 0)\n",
    "feature_shape_cat = torch.cat(feature_shape_list, dim = 0)\n",
    "feature_color_cat = torch.cat(feature_color_list, dim = 0)\n",
    "out_all_cat = torch.cat(out_all_list, dim = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = feature_all_cat\n",
    "dimension = 512\n",
    "df_name = './df_512_mask_all.csv'\n",
    "\n",
    "img_label_list = matrix.tolist()\n",
    "for j in range(0,len(img_label_list)):\n",
    "    img_label_list[j].append(img_label_dict[j])\n",
    "    \n",
    "img_label_df = pd.DataFrame(img_label_list)\n",
    "img_label_df_new = img_label_df.rename(columns={dimension: 'modelId'})\n",
    "testset.meta_new = testset.meta.rename(columns={'id': 'modelId'})\n",
    "total_df = pd.merge(img_label_df_new, testset.meta_new, on=\"modelId\")\n",
    "total_df.to_csv(df_name, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = feature_shape_cat\n",
    "dimension = 512\n",
    "df_name = './df_512_mask_shape.csv'\n",
    "\n",
    "img_label_list = matrix.tolist()\n",
    "for j in range(0,len(img_label_list)):\n",
    "    img_label_list[j].append(img_label_dict[j])\n",
    "    \n",
    "img_label_df = pd.DataFrame(img_label_list)\n",
    "img_label_df_new = img_label_df.rename(columns={dimension: 'modelId'})\n",
    "testset.meta_new = testset.meta.rename(columns={'id': 'modelId'})\n",
    "total_df = pd.merge(img_label_df_new, testset.meta_new, on=\"modelId\")\n",
    "total_df.to_csv(df_name, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = feature_color_cat\n",
    "dimension = 512\n",
    "df_name = './df_512_mask_color.csv'\n",
    "\n",
    "img_label_list = matrix.tolist()\n",
    "for j in range(0,len(img_label_list)):\n",
    "    img_label_list[j].append(img_label_dict[j])\n",
    "    \n",
    "img_label_df = pd.DataFrame(img_label_list)\n",
    "img_label_df_new = img_label_df.rename(columns={dimension: 'modelId'})\n",
    "testset.meta_new = testset.meta.rename(columns={'id': 'modelId'})\n",
    "total_df = pd.merge(img_label_df_new, testset.meta_new, on=\"modelId\")\n",
    "total_df.to_csv(df_name, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# End."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
